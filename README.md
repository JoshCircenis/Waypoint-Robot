# Waypoint-Robot
## Table of Contents
* [About](#About)
* [Overview](#Overview)
  * [Raspberry Pi](#Raspberry-Pi)
  * [Arduino](#Arduino)
* [Improvements](#Improvements)

## About
This project was done for a term final in an Operating Systems class. The idea was to create an autonomous robot that hosts a web server that a user can send commands through, this robot would then be used as a platform for autonomous data collection and/or monitoring. The robot consisted of a chassis, a Raspberry Pi, an Arduino Uno, a lipo battery, and various sensors.

## Overview
#### Raspberry Pi
To build an interface that a user can use to interact with the robot the Raspberry Pi is hosting a locally accessible web page using a web application framework called Flask. Using Flask the Pi hosts the web server and loads a front-facing HTML page that enables Python functions to be run as a result of user interaction. The HTML page is very simple and allows the user to input a command in a text box which will be received on the Pi and sent to the Arduino over a USB port, then any reply from the Arduino through the USB port would be written to the user interface. In this way, the Raspberry Pi acts as an interface between the user and the Arduino which in turn acts as a hardware interface.

![image](https://github.com/JoshCircenis/Waypoint-Robot/assets/98178221/32bbfd60-07f3-42b8-8f3d-222ca6bcbc0b)

#### Arduino
As previously stated the Arduino acts as a hardware interface that receives commands from the Raspberry PI through a USB connection. The autonomous movement will be implemented as a waypoint system where the user can send geographic coordinates to the robot and it will autonomously navigate to the point. For the robot to do this it first has to know where it is located and where it needs to go. This will be done using a NEO-6M GPS module which is compatible with the Arduino using the “TinyGPS++” and “SoftwareSerial.h”. The GPS module can determine the coordinates of the robot, the number of satellites in range, the speed, and the course. This is enough to accurately maneuver to the given coordinate autonomously, however, at slow speeds, the speed and course function are not accurate. This means that the robot will need additional sensors to complete the task. To get the heading, the robot is equipped with a magnetometer using the “Wire.h” and “HMC5883L.h” Arduino libraries. A magnetometer is a digital compass and after calibration, it will serve as an accurate way for the robot to determine its orientation.

Now that the robot is capable of obtaining the necessary information to navigate autonomously we can begin to implement autonomous navigation. The first step is to set up the necessary motion functions for the robot. The robot chassis is the base of an Elegoo "Smart Robot Car Kit" which consists of two acrylic plates connected with standoffs, four motors, and an “L298N” dual channel h-bridge type motor controller. This means that the direction of each motor is controlled by two digital outputs and the speed is controlled by a PWM output. The robot is configured such that two of the four motors are grouped in pairs giving us differential (tank) steering. The next feature to implement is a “rotate to heading” function. For the robot to navigate autonomously it will need the ability to automatically rotate to a desired heading. This was done using only the proportional term of a PID loop with the magnetometer orientation as an input and the PWM levels as an output. To efficiently rotate to the heading the optimal direction to turn, clockwise or counterclockwise, is determined using the following equations “(current angle - desired angle + 360) % 360” and “(desired angle - current angle + 360) % 360” where “current angle” is the orientation of the robot in regards to magnetic north and “desired angle” is the desired heading of the robot. This will give us the number of degrees that it would take to reach the heading both in both the clockwise and counter-clockwise directions. To get the appropriate speed the distance (in degrees) we are from our target heading is multiplied by the speed output, this allows the robot to set its speed so as to not overshoot the target but instead to speed up and slow down proportional to the distance from the target in a feedback loop. This is done with the following equation for counterclockwise
“| | 360 - desired angle | - | 360 - current angle| * 255” and “| desired angle - current angle| * 255” for clockwise where 255 represents the full speed of the motors.

Since the robot can now move and turn accurately it needs to determine a course to follow. The first value that is needed is the bearing (angle) of the line formed by the coordinates sent by the user and the coordinates of the robot. This can be done using the bearing equation derived from the [Haversine formula](https://community.esri.com/t5/coordinate-reference-systems-blog/distance-on-a-sphere-the-haversine-formula/ba-p/902128#:~:text=All%20of%20these%20can%20be,longitude%20of%20the%20two%20points.). Then the Haversine formula can be used to determine the distance between the two points. The control loop utilized for the robot is as follows, first, the robot gets the bearing to the defined point and then orients towards the point, it then drives forward until it reaches within a specified error of the point or goes off course. We can determine if the robot is off course by getting the heading from the magnetometer. If this value is outside of a certain range from the target then again the robot will calculate the heading reorient and drive forward until the goal is reached or another course correction must be made. In this manner, the robot autonomously navigates to the desired location correcting its course when necessary. The flow chart below shows the navigation control algorithm where “Orient towards waypoint?” and “Waypoint reached?” are checked continuously over the period of navigation.

![image](https://github.com/JoshCircenis/Waypoint-Robot/assets/98178221/eca6abab-dbfb-4580-bc60-388581380987)

At this point, the user can create their own custom operations or data collection methods and then have the robot complete these tasks by sending a custom command through the user interface to the Arduino. Below is a picture of the completed robot.

![IMG_3198](https://github.com/JoshCircenis/Waypoint-Robot/assets/98178221/afdd4004-9973-40de-89e4-5ce28f5457f6)

## Improvements
The robot functions well and can navigate autonomously to a given point and record sensor data, however, at this point all commands must be sent one at a time through the user interface. In order to improve this system the user interface could be changed to accept an order of commands or a JSON object that specifies when and where certain tasks should be executed. Also, the data collected by the Arduino could be formatted such that a user can download it directly from the interface instead of displaying it as plain text. As for the robot itself, the accuracy in positioning could be improved by utilizing more accurate sensors, and currently, the robot does not track perfectly straight so usually several course corrections must be made to reach a specified point. This could be fixed by improving the navigation algorithm to actively change course as error builds up instead of waiting until a threshold is met to correct the course. These changes would improve the robot's efficiency and utility, along these same lines, the robot currently only uses its current position and a setpoint to navigate. In this state, the robot can not account for obstructions in its path or dynamic surroundings such as people, this limits what environments the robot is useful in but by including additional sensors such as LIDAR, time of flight sensors, or ultrasonic rangefinders and incorporating these into the navigation the robot would be able to avoid obstacles and be useful in a greater variety of environments.
